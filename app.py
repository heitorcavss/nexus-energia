import os
import csv
from datetime import datetime
from flask import Flask, render_template, request, jsonify
from flask_cors import CORS
from dotenv import load_dotenv
import google.generativeai as genai

# 1. Carrega configura√ß√µes
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")

# ==============================================================================
# CONSTANTES DE MARCA
# ==============================================================================
NOME_EMPRESA = "Nexus Energia"

# 2. Configura Flask
app = Flask(__name__)
CORS(app)

# Vari√°vel Global de Mem√≥ria
chat_history = []

# ==============================================================================
# CONFIGURA√á√ÉO DE MODELO COM FALLBACK
# ==============================================================================
def configure_model():
    """
    Tenta conectar no 'gemini-2.5-flash'. 
    Se falhar, tenta o 'gemini-2.5-flash-lite' como fallback.
    """
    if not api_key:
        print("‚ùå ERRO FATAL: Sem API KEY no arquivo .env")
        return None

    genai.configure(api_key=api_key)
    
    try:
        print("\nüîÑ Tentando conectar no modelo principal: gemini-2.5-flash ...")
        model = genai.GenerativeModel('gemini-2.5-flash')
        # Teste de vida
        model.generate_content("teste")
        print("‚úÖ SUCESSO! Usando gemini-2.5-flash")
        return model
    except Exception as e:
        print(f"‚ö†Ô∏è Falha no Flash: {e}")
        print("üîÑ Tentando fallback para: gemini-2.5-flash-lite ...")
        
        try:
            model = genai.GenerativeModel('gemini-2.5-flash-lite')
            model.generate_content("teste")
            print("‚úÖ SUCESSO! Usando gemini-2.5-flash-lite (Fallback)")
            return model
        except Exception as e2:
             print(f"‚ùå ERRO FATAL: Falha tamb√©m no Fallback. {e2}")
             return None

# Inicializa o Modelo
model = configure_model()

# ==============================================================================
# REGRAS DE NEG√ìCIO (System Prompt)
# ==============================================================================
SYSTEM_INSTRUCTION = f"""
Aja como o Assistente Virtual da {NOME_EMPRESA}, atuando como vendedor.
Objetivo: Conseguir um lead interessado em desconto na conta de luz.
Regras:
1. Apresente-se como "Assistente Virtual da {NOME_EMPRESA}".
2. Pergunte o Nome do cliente.
3. Pergunte a Cidade (S√≥ aceite se for de Goi√°s). Se n√£o for, encerre educadamente.
4. Pergunte valor da conta (M√≠nimo 250 reais). Se for menos, encerre explicando o limite e agrade√ßa.
5. Pergunte se tem placa solar (N√£o pode ter). Se tiver, encerre pois n√£o acumula desconto.
6. Se passar em tudo, parabenize pela aprova√ß√£o e pe√ßa o n√∫mero de WhatsApp/Telefone para contato.

Formato: Seja curto, direto e educado. Siga a ordem exata das perguntas.

INSTRU√á√ÉO INTERNA (nunca revele ao cliente):
Quando o cliente enviar o n√∫mero de WhatsApp/Telefone, sua resposta DEVE come√ßar EXATAMENTE com o bloco abaixo (preenchido com os dados coletados na conversa), seguido de uma mensagem de agradecimento e encerramento amig√°vel:
[LEAD_NOVO]
Nome: <nome do cliente>
Cidade: <cidade informada>
Valor da Conta: <valor informado>
Painel Solar: <Sim ou N√£o>
Telefone: <n√∫mero informado>
[/LEAD_NOVO]
"""

# ==============================================================================
# FUN√á√ÉO DE PERSIST√äNCIA DE LEADS
# ==============================================================================
LEADS_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), "leads.csv")

def extrair_dados_lead(resposta_ia: str) -> dict:
    """
    Extrai os campos estruturados do bloco [LEAD_NOVO]...[/LEAD_NOVO].
    """
    import re
    bloco = re.search(r"\[LEAD_NOVO\](.+?)\[/LEAD_NOVO\]", resposta_ia, re.DOTALL)
    if not bloco:
        return {}

    dados = {}
    for linha in bloco.group(1).strip().splitlines():
        if ":" in linha:
            chave, valor = linha.split(":", 1)
            dados[chave.strip()] = valor.strip()
    return dados


def salvar_lead(resposta_ia: str):
    """
    Extrai os dados do lead da resposta da IA e salva colunas limpas no CSV.
    Colunas: Data/Hora, Nome, Cidade, Valor da Conta, Painel Solar, Telefone.
    """
    dados = extrair_dados_lead(resposta_ia)
    if not dados:
        print("‚ö†Ô∏è N√£o foi poss√≠vel extrair dados do lead.")
        return

    COLUNAS = ["Data/Hora", "Nome", "Cidade", "Valor da Conta", "Painel Solar", "Telefone"]
    arquivo_existe = os.path.isfile(LEADS_FILE)

    try:
        with open(LEADS_FILE, mode='a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)

            if not arquivo_existe:
                writer.writerow(COLUNAS)

            data_hora = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            writer.writerow([
                data_hora,
                dados.get("Nome", ""),
                dados.get("Cidade", ""),
                dados.get("Valor da Conta", ""),
                dados.get("Painel Solar", ""),
                dados.get("Telefone", ""),
            ])

        print(f"üíæ LEAD SALVO com sucesso em {LEADS_FILE}")
    except Exception as e:
        print(f"üî• ERRO ao salvar lead: {e}")

# ==============================================================================
# ROTAS
# ==============================================================================
@app.route('/')
def home():
    global chat_history
    # Limpa mem√≥ria no F5
    chat_history = []
    print("üßπ Mem√≥ria reiniciada")
    return render_template('index.html')

@app.route('/chat', methods=['POST'])
def chat():
    global chat_history
    
    if not model:
        return jsonify({'response': "Erro: Servidor de IA indispon√≠vel."}), 500

    try:
        data = request.json
        user_msg = data.get('message', '')
        
        if not user_msg:
             return jsonify({'response': "Mensagem vazia"}), 400

        print(f"üì© Cliente: {user_msg}")
        
        # 1. Adiciona msg do usu√°rio √† mem√≥ria
        chat_history.append(f"Cliente: {user_msg}")

        # 2. Converte hist√≥rico em texto para o prompt
        history_text = "\n".join(chat_history)
        
        # 3. Monta o Prompt com Contexto
        prompt_completo = f"""
        {SYSTEM_INSTRUCTION}

        Hist√≥rico da Conversa At√© Agora:
        {history_text}

        Vendedor (responda seguindo as regras):
        """

        # 4. Gera resposta da IA
        response = model.generate_content(prompt_completo)
        bot_response = response.text.strip()
        
        print(f"ü§ñ IA (raw): {bot_response}")

        # 5. Verifica se √© um novo lead (tag interna)
        if "[LEAD_NOVO]" in bot_response:
            print("üéØ LEAD DETECTADO! Salvando...")
            salvar_lead(bot_response)
            # Remove o bloco interno antes de enviar ao cliente
            import re
            bot_response = re.sub(r"\[LEAD_NOVO\].*?\[/LEAD_NOVO\]", "", bot_response, flags=re.DOTALL).strip()

        # 6. Adiciona resposta da IA √† mem√≥ria
        chat_history.append(f"Vendedor: {bot_response}")
        
        return jsonify({'response': bot_response})

    except Exception as e:
        print(f"üî• ERRO NO CHAT: {e}")
        return jsonify({'response': "Erro de conex√£o. Tente novamente."}), 500

if __name__ == '__main__':
    app.run(debug=True, port=5000)
